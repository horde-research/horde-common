{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56094055-3390-4ec8-837f-693a0658aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U langchain\n",
    "!pip install -q einops\n",
    "!pip install -q datasets\n",
    "# !pip install sentencepiece #optional, only for some models on old LLama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae84674-454d-48eb-b04d-4627a3bee001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e2dda0-4698-4422-9b42-1046d1efa1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,concatenate_datasets, Dataset\n",
    "\n",
    "mmlu   = load_dataset(\"kz-transformers/mmlu-translated-kk\")[\"validation\"]\n",
    "const  = load_dataset(\"kz-transformers/kazakh-constitution-mc\")[\"test\"]\n",
    "dastur = load_dataset(\"kz-transformers/kazakh-dastur-mc\")[\"test\"]\n",
    "ent    = load_dataset(\"kz-transformers/kazakh-unified-national-testing-mc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf83bfb5-930e-49e4-9025-bba9d18b1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mmlu = \"\"\"Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\\n\\n\n",
    "\n",
    "Cұрақ: {prompt}\\n\n",
    "A) {a}\\n\n",
    "B) {b}\\n\n",
    "C) {c}\\n\n",
    "D) {d}\\n\n",
    "\n",
    "Жауап:\"\"\"\n",
    "\n",
    "prompt_mmlu = PromptTemplate(template=template_mmlu, input_variables=['prompt', 'a', 'b', 'c', 'd'])\n",
    "\n",
    "template_ent = \"\"\"Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\\n\\n\n",
    "\n",
    "Cұрақ: {prompt}\\n\n",
    "A) {a}\\n\n",
    "B) {b}\\n\n",
    "C) {c}\\n\n",
    "D) {d}\\n\n",
    "E) {e}\\n\n",
    "F) {f}\\n\n",
    "G) {g}\\n\n",
    "H) {h}\\n\n",
    "\n",
    "Жауап:\"\"\"\n",
    "\n",
    "prompt_ent = PromptTemplate(template=template_ent, input_variables=['prompt', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445ae77d-adb4-478c-bc45-42f461ce51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text_mmlu(example):\n",
    "    text = prompt_mmlu.format(prompt=example['Question'],\n",
    "                         a=example['Option A'],\n",
    "                         b=example['Option B'],\n",
    "                         c=example['Option C'],\n",
    "                         d=example['Option D'])\n",
    "    return {\"text\": text}\n",
    "\n",
    "def format_text_ent(example):\n",
    "    text = prompt_ent.format(prompt=example['question'],\n",
    "                         a=example['A'],\n",
    "                         b=example['B'],\n",
    "                         c=example['C'],\n",
    "                         d=example['D'],\n",
    "                         e=example['E'],\n",
    "                         f=example['F'],\n",
    "                         g=example['G'],\n",
    "                         h=example['H'])\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61df31e8-0590-4fe4-9952-856de611f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu = mmlu.map(format_text_mmlu)\n",
    "const = const.map(format_text_mmlu)\n",
    "dastur = dastur.map(format_text_mmlu)\n",
    "ent = ent.map(format_text_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e78cfe-436e-4ff2-8893-db9ff69f2a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\n",
      "\n",
      "\n",
      "\n",
      "Cұрақ: 18 арқылы жасалған Z_24 циклдік топшасының реті бар\n",
      "\n",
      "A) 4\n",
      "\n",
      "B) 8\n",
      "\n",
      "C) 12\n",
      "\n",
      "D) 6\n",
      "\n",
      "\n",
      "Жауап:\n",
      "**************************************************\n",
      "Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\n",
      "\n",
      "\n",
      "\n",
      "Cұрақ: Қазақстан Республикасы өзін қандай мемлекет ретінде орнықтырады?\n",
      "\n",
      "A) Автократиялық\n",
      "\n",
      "B) Демократиялық, зайырлы, құқықтық және әлеуметтік\n",
      "\n",
      "C) Тоталитарлық\n",
      "\n",
      "D) Монархиялық\n",
      "\n",
      "\n",
      "Жауап:\n",
      "**************************************************\n",
      "Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\n",
      "\n",
      "\n",
      "\n",
      "Cұрақ: Тыйым деген не?\n",
      "\n",
      "A) Қазақ халқының той рәсімі\n",
      "\n",
      "B) Қазақ халқының тәрбиелік құралы\n",
      "\n",
      "C) Қазақ халқының музыкалық құралы\n",
      "\n",
      "D) Қазақ халқының аспап-құралы\n",
      "\n",
      "\n",
      "Жауап:\n",
      "**************************************************\n",
      "Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. Қазақстан мәдениеті, ғылым, тарих және басқа да салалар бойынша көптаңдаулы сұрақтарға жауап беріңіз. Сұрақты және берілген жауап нұсқаларын мұқият оқып, ең дұрысын бір ғана әріппен (A, B, C, т.б.) белгілеңіз.\n",
      "\n",
      "\n",
      "\n",
      "Cұрақ: Антропогендік факторларға жататындар:\n",
      "\n",
      "A) Жер сілкіну.\n",
      "\n",
      "B) Жыртқыштардың жемтігіне шабуылы.\n",
      "\n",
      "C) Ауа температурасының қолайсыздығы.\n",
      "\n",
      "D) Батпақты құрғату.\n",
      "\n",
      "E) Ауа массасындағы қозғалыстар.\n",
      "\n",
      "F) None\n",
      "\n",
      "G) None\n",
      "\n",
      "H) None\n",
      "\n",
      "\n",
      "Жауап:\n"
     ]
    }
   ],
   "source": [
    "print(mmlu['text'][0])\n",
    "print(\"*\"*50)\n",
    "print(const['text'][0])\n",
    "print(\"*\"*50)\n",
    "print(dastur['text'][0])\n",
    "print(\"*\"*50)\n",
    "print(ent['biology']['text'][67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e810b6c-a655-4296-aba3-ca28be29b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu = mmlu.to_pandas()\n",
    "const = const.to_pandas()\n",
    "dastur = dastur.to_pandas()\n",
    "ent = pd.concat([ent[i].to_pandas() for i in ent])\n",
    "ent['idx'] = ent.index.astype(str)+\"-\"+ent['subject']\n",
    "mmlu['idx'] = mmlu.index.astype(str)+\"-mmlu\"\n",
    "const['idx'] = const.index.astype(str)+\"-const\"\n",
    "dastur['idx'] = dastur.index.astype(str)+\"-dastur\"\n",
    "ent = ent.rename({'correct_answer': 'answer'},axis=1)\n",
    "mmlu = mmlu.rename({'Correct Answer': 'answer'},axis=1)\n",
    "const = const.rename({'Correct Answer': 'answer'},axis=1)\n",
    "dastur = dastur.rename({'Correct Answer': 'answer'},axis=1)\n",
    "columns = [\"answer\", \"text\", \"idx\"]\n",
    "mmlu_like = pd.concat([mmlu[columns], const[columns], dastur[columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005682e2-d6e5-4bce-a445-dd0399a9b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "ent_ds = Dataset.from_pandas(ent[columns])\n",
    "mmlu_like_ds = Dataset.from_pandas(mmlu_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744ed362-a518-4d44-bc2b-25a8ff05f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"TilQazyna/llama-kaz-instruct-8B-1\"\n",
    "#model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "#model_id = \"google/gemma-2-2b-it\"\n",
    "#model_id = \"google/gemma-2-9b-it\"\n",
    "#model_id = \"AmanMussa/llama2-kazakh-7b\"\n",
    "#model_id = \"LLaMAX/LLaMAX3-8B\"\n",
    "#model_id = \"IrbisAI/Irbis-7b-v0.1\"# at the end of all experiments\n",
    "model_id = \"AmanMussa/llama2-kazakh-7b-ver2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e576aa98-6048-4594-873e-b21ee6d659ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07570f417c44bf59234165014e641cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2559b7dfa87c427c904d3db981353a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9d1f18e3864fa995cd79f0de5d3d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a634466af71f4a4fb8549f3f0b0d61b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778d8f9-90ab-4f5e-b138-c997c479f666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a02df4013c409bbd5c20648f520750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487868dc7a4d444ebd183b840e633988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee64a0ba5497411b9d6be5d65598f64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a88dce64201437f9dec096138631b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee9ad33f1df42e086f726a1c9e52279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ad94ca0b1a4925a9ea6b7c747f6fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db2209-e10c-4cf6-a784-b55e065ae726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0df38-b7b7-468f-b5be-8a50653631b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(text, mode=\"mmlu\"):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits[0, -1]\n",
    "\n",
    "    del inputs\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    options_list = [(logits[tokenizer(' A').input_ids[-1]], 'A'),\n",
    "                    (logits[tokenizer(' B').input_ids[-1]], 'B'),\n",
    "                    (logits[tokenizer(' C').input_ids[-1]], 'C'),\n",
    "                    (logits[tokenizer(' D').input_ids[-1]], 'D')]\n",
    "    if mode == \"ent\":\n",
    "        options_list= options_list+[(logits[tokenizer(' E').input_ids[-1]], 'E'),\n",
    "                                    (logits[tokenizer(' F').input_ids[-1]], 'F'),\n",
    "                                    (logits[tokenizer(' G').input_ids[-1]], 'G'),\n",
    "                                    (logits[tokenizer(' H').input_ids[-1]], 'H')]\n",
    "    options_list = sorted(options_list, reverse=True)\n",
    "    return options_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a2d90-f0f7-48e2-9d6a-b217a728901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "answers_mmlu = []\n",
    "bar = tqdm(enumerate(mmlu_like_ds), total=len(mmlu_like_ds))\n",
    "for i, data in bar:\n",
    "    ans_list = get_ans(data['text'])\n",
    "    predict = ans_list[1]\n",
    "    answer = data['answer']\n",
    "    if predict == answer:\n",
    "        acc = 1\n",
    "    else:\n",
    "        acc = 0\n",
    "    idx = data['idx']\n",
    "    answers_mmlu.append({'idx': idx, 'answer': answer, 'predict': predict, 'acc': acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46e645-3fed-4c2a-aaa6-fd7c28f121ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "answers_ent = []\n",
    "bar = tqdm(enumerate(ent_ds), total=len(ent_ds))\n",
    "for i, data in bar:\n",
    "    ans_list = get_ans(data['text'], mode=\"ent\")\n",
    "    predict = ans_list[1]\n",
    "    answer = data['answer']\n",
    "    if predict == answer:\n",
    "        acc = 1\n",
    "    else:\n",
    "        acc = 0\n",
    "    idx = data['idx']\n",
    "    answers_ent.append({'idx': idx, 'answer': answer, 'predict': predict, 'acc': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b57de-63fb-49ba-aec4-5d321855d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_mmlu = pd.DataFrame(answers_mmlu)\n",
    "answers_ent = pd.DataFrame(answers_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf90af6-1e9b-4e60-872e-838505291ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((answers_mmlu,answers_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412186a-6267-4167-885c-464e740d4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'] = df.idx.apply(lambda x: x.replace(x.split('-')[0]+\"-\",\"\"))\n",
    "final = pd.merge(df.groupby('dataset').acc.sum(), df.groupby('dataset').acc.count(), on=['dataset'])\n",
    "final['acc'] = final.acc_x/final.acc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db0d06-2cfc-4c9b-93d2-54340355a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0aad4-d29b-484b-94b5-049b304964bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['acc'].head(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d121b87-b583-4862-b89d-0e89cf031eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"_\".join(model_id.split(\"/\"))\n",
    "final.to_csv(f\"final-{name}.csv\")\n",
    "df.to_csv(f\"df-{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080301f-fceb-47aa-9b5f-42c2855fc238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
