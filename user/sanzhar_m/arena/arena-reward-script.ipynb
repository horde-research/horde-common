{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9f32811-48e4-49d6-90d8-e2a38b2d70f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "818db1a2-428f-455c-b4b0-dc73429ff847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec2b9aba-490e-4f62-9a7b-ae5f6786f2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Arena_QS_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f8d0ab-8e55-4cc5-a668-733c5cf15428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['group', 'category', 'subcategory', 'source',\n",
    "       'text', 'WHY_QS', 'WHAT_QS', 'HOW_QS', 'DESCRIBE_QS', 'ANALYZE_QS',\n",
    "       'WHY_QS_ANS', 'WHAT_QS_ANS', 'HOW_QS_ANS', 'DESCRIBE_QS_ANS',\n",
    "       'ANALYZE_QS_ANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5671ca6f-c544-4503-b6ae-fc1ee216ece2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7799/7799 [03:29<00:00, 37.26it/s] \n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    num_tokens += len(encoder.encode(' '.join([row[col] for col in cols])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf6fbd74-371c-4694-9b0c-f0276bdd48c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208935118"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7da12465-d3f8-498c-b889-3ec8658a9655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 file(s).\n"
     ]
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"WHY\", description=\"Quality score (0 or 1) for the first question-answer pair.\"),\n",
    "    ResponseSchema(name=\"WHAT\", description=\"Quality score (0 or 1) for the second question-answer pair.\"),\n",
    "    ResponseSchema(name=\"HOW\", description=\"Quality score (0 or 1) for the third question-answer pair.\"),\n",
    "    ResponseSchema(name=\"DESCRIBE\", description=\"Quality score (0 or 1) for the fourth question-answer pair.\"),\n",
    "    ResponseSchema(name=\"ANALYZE\", description=\"Quality score (0 or 1) for the fifth question-answer pair.\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "def format_gpt4o_batch_prompt(row: pd.Series, dataset_name: str, index: int, gpt: str = 'gpt-4o-mini'):\n",
    "    \"\"\"\n",
    "    Generate a JSON payload for GPT-4o-mini evaluation prompt based on a DataFrame row.\n",
    "    The prompt clearly marks where each question-answer pair starts and ends.\n",
    "    \"\"\"\n",
    "    qa_mapping = [\n",
    "        (\"WHY_QS\", \"WHAT_QS_ANS\"),\n",
    "        (\"WHAT_QS\", \"HOW_QS_ANS\"),\n",
    "        (\"HOW_QS\", \"DESCRIBE_QS_ANS\"),\n",
    "        (\"DESCRIBE_QS\", \"ANALYZE_QS_ANS\"),\n",
    "        (\"ANALYZE_QS\", \"ANALYZE_QS_ANS\")\n",
    "    ]\n",
    "    \n",
    "    text = row[\"text\"]\n",
    "    \n",
    "    qa_sections = []\n",
    "    for i, (q_col, a_col) in enumerate(qa_mapping, start=1):\n",
    "        question = row.get(q_col, \"\")\n",
    "        answer = row.get(a_col, \"\")\n",
    "        if pd.notnull(question) and pd.notnull(answer) and question.strip() and answer.strip():\n",
    "            section = (\n",
    "                f\"=== Сұрақ {i} басталады ===\\n\"\n",
    "                f\"Сұрақ: {question}\\n\"\n",
    "                f\"Жауап: {answer}\\n\"\n",
    "                f\"=== Сұрақ {i} аяқталды ===\"\n",
    "            )\n",
    "            qa_sections.append(section)\n",
    "    \n",
    "    prompt_content = (\n",
    "        f\"{text}\\n\\n\" +\n",
    "        \"\\n\\n\".join(qa_sections) +\n",
    "        \"\\n\\n\" +\n",
    "        \"Жоғарыдағы мәтін мен сұрақ-жауап жұптарын мұқият оқыңыз. Әр жұптың сапасын бағалаңыз: \"\n",
    "        \"егер жұп сапалы болса 1, ал сапасыз болса 0 деп белгілеңіз. \"\n",
    "        \"Нәтижені тек төмендегі JSON құрылымында, қосымша түсініктеме бермей көрсетіңіз:\\n\\n\" +\n",
    "        format_instructions\n",
    "    )\n",
    "    \n",
    "    payload = {\n",
    "        \"custom_id\": f\"{dataset_name}-{index}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": gpt,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": (\n",
    "                        \"Сіз қазақ тілінде жауап беретін білімді, пайдалы көмекшісіз. \"\n",
    "                        \"Мәтін мен сұрақ-жауап жұптарын мұқият оқып, әр жұптың сапасын бағалаңыз. \"\n",
    "                        \"Жауаптарыңызды жоғарыда көрсетілген JSON құрылымында, қосымша түсініктеме немесе мәтінсіз беріңіз.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt_content\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 150,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return payload\n",
    "\n",
    "\n",
    "max_file_size = 200 * 1024 * 1024\n",
    "file_count = 1\n",
    "current_file_size = 0\n",
    "\n",
    "current_filename = f\"batch_requests_part_{file_count}.jsonl\"\n",
    "current_file = open(current_filename, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    payload = format_gpt4o_batch_prompt(row, \"extended_law\", i)\n",
    "    json_line = json.dumps(payload, ensure_ascii=False) + \"\\n\"\n",
    "    line_size = len(json_line.encode(\"utf-8\"))\n",
    "    \n",
    "    if current_file_size + line_size > max_file_size:\n",
    "        current_file.close()\n",
    "        file_count += 1\n",
    "        current_filename = f\"batch_requests_part_{file_count}.jsonl\"\n",
    "        current_file = open(current_filename, \"w\", encoding=\"utf-8\")\n",
    "        current_file_size = 0\n",
    "    \n",
    "    current_file.write(json_line)\n",
    "    current_file_size += line_size\n",
    "\n",
    "current_file.close()\n",
    "\n",
    "print(f\"Created {file_count} file(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa0dba5a-3593-4536-b2ef-bccdf995e182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch_requests_part_1.jsonl...\n",
      "Uploaded file batch_requests_part_1.jsonl with ID: file-2E39vqi2NdaHMDS37te9Ne\n",
      "Uploading batch_requests_part_2.jsonl...\n",
      "Uploaded file batch_requests_part_2.jsonl with ID: file-V7cFVi5Re3Utq2WAQ9brdm\n",
      "Uploading batch_requests_part_3.jsonl...\n",
      "Uploaded file batch_requests_part_3.jsonl with ID: file-CAaa6d1FWByTduLFSwbMqJ\n",
      "Uploading batch_requests_part_4.jsonl...\n",
      "Uploaded file batch_requests_part_4.jsonl with ID: file-RTaj3YDgJVU5fe3Ayvq71S\n",
      "Uploading batch_requests_part_5.jsonl...\n",
      "Uploaded file batch_requests_part_5.jsonl with ID: file-ADPofjrcH4mP21LS2jM1C7\n",
      "Uploading batch_requests_part_6.jsonl...\n",
      "Uploaded file batch_requests_part_6.jsonl with ID: file-F6D7TWACmwrkddxasaLJg7\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=openai_key)\n",
    "\n",
    "uploaded_file_ids = []\n",
    "for part in range(1, file_count + 1):\n",
    "    filename = f\"batch_requests_part_{part}.jsonl\"\n",
    "    print(f\"Uploading {filename}...\")\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    uploaded_file_ids.append(batch_input_file.id)\n",
    "    print(f\"Uploaded file {filename} with ID: {batch_input_file.id}\")\n",
    "\n",
    "batches = []\n",
    "for file_id in uploaded_file_ids:\n",
    "    batches.append(client.batches.create(\n",
    "        input_file_id=file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": \"nightly eval job\"\n",
    "        }\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ec6499-2bef-4d78-bc24-c896de771e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "611a5972-5b49-457a-af85-7b311a521632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID: batch_67b5fd2e902881909af9275258629834\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:58\n",
      "In progress at: 2025-02-19 15:48:04\n",
      "Finalizing at: 2025-02-19 16:44:53\n",
      "Completed at: 2025-02-19 16:48:43\n",
      "Expires at: 2025-02-20 15:47:58\n",
      "Output File ID: file-88EuGsnXxFqbVVBAS3HwCd\n",
      "\n",
      "Batch ID: batch_67b5fd2dbe8481909e5fed2e2d89072a\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:57\n",
      "In progress at: 2025-02-19 15:48:05\n",
      "Finalizing at: 2025-02-19 16:43:34\n",
      "Completed at: 2025-02-19 16:46:36\n",
      "Expires at: 2025-02-20 15:47:57\n",
      "Output File ID: file-DRrX99fsFYmRm3MeN2KaQU\n",
      "\n",
      "Batch ID: batch_67b5fd2d1da88190a8117a3f92f32cf3\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:57\n",
      "In progress at: 2025-02-19 15:48:06\n",
      "Finalizing at: 2025-02-19 16:56:43\n",
      "Completed at: 2025-02-19 17:05:34\n",
      "Expires at: 2025-02-20 15:47:57\n",
      "Output File ID: file-Q2rouDGautU5xcEWMuAfvA\n",
      "\n",
      "Batch ID: batch_67b5fd2c6be88190aeb0c3a72ec776ed\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:56\n",
      "In progress at: 2025-02-19 15:48:07\n",
      "Finalizing at: 2025-02-19 16:54:23\n",
      "Completed at: 2025-02-19 16:57:28\n",
      "Expires at: 2025-02-20 15:47:56\n",
      "Output File ID: file-E3TVsow9NP9g6B3nfKCQUe\n",
      "\n",
      "Batch ID: batch_67b5fd2bdd108190ad63f91c0c632f47\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:55\n",
      "In progress at: 2025-02-19 15:48:05\n",
      "Finalizing at: 2025-02-19 16:42:29\n",
      "Completed at: 2025-02-19 16:44:07\n",
      "Expires at: 2025-02-20 15:47:55\n",
      "Output File ID: file-9ExVVHZBLavXzKVTghMKWk\n",
      "\n",
      "Batch ID: batch_67b5fd2b51fc8190a05c6f291f1577d4\n",
      "Status: completed\n",
      "Created at: 2025-02-19 15:47:55\n",
      "In progress at: 2025-02-19 15:48:05\n",
      "Finalizing at: 2025-02-19 16:57:46\n",
      "Completed at: 2025-02-19 17:05:14\n",
      "Expires at: 2025-02-20 15:47:55\n",
      "Output File ID: file-U1k8r6cvJiVJJyfgw6BTWC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def format_timestamp(ts):\n",
    "    return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S') if ts is not None else \"N/A\"\n",
    "\n",
    "batches = client.batches.list(limit=6)\n",
    "\n",
    "output_files = []\n",
    "\n",
    "for batch in batches.data:\n",
    "    batch_id = batch.id\n",
    "    print(\"Batch ID:\", batch_id)\n",
    "    \n",
    "    batch_details = client.batches.retrieve(batch_id)\n",
    "    status = batch_details.status\n",
    "    print(\"Status:\", status)\n",
    "    print(\"Created at:\", format_timestamp(batch_details.created_at))\n",
    "    print(\"In progress at:\", format_timestamp(batch_details.in_progress_at))\n",
    "    print(\"Finalizing at:\", format_timestamp(batch_details.finalizing_at))\n",
    "    print(\"Completed at:\", format_timestamp(batch_details.completed_at))\n",
    "    print(\"Expires at:\", format_timestamp(batch_details.expires_at))\n",
    "\n",
    "    output_file_id = batch_details.output_file_id\n",
    "    if output_file_id:\n",
    "        print(\"Output File ID:\", output_file_id)\n",
    "        output_files.append(output_file_id)\n",
    "    else:\n",
    "        print(\"Output File ID not available yet for this batch.\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ym",
   "name": "common-cu121.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m119"
  },
  "kernelspec": {
   "display_name": "YM",
   "language": "python",
   "name": "ym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
